agent_name: "ASE"

model:
  actor_net: "fc_2layers_128units"
  actor_init_output_scale: 0.01
  actor_std_type: "CONSTANT"
  action_std: 1.
  
  critic_net: "fc_2layers_512units"

  disc_net: "fc_2layers_128units"
  disc_init_output_scale: 1.0
  
  enc_net: "fc_2layers_1024units"
  latent_dim: 64

optimizer:
    type: "Adam"
    learning_rate: 3e-4

discount: 0.99
steps_per_iter: 32
iters_per_output: 500
test_episodes: 32
normalizer_samples: 100000000

update_epochs: 5
batch_size: 4
td_lambda: 0.95
ppo_clip_ratio: 0.2
norm_adv_clip: 4.0
action_bound_weight: 10.0
action_entropy_weight: 0.005
action_reg_weight: 0.0
critic_loss_weight: 1.0

disc_loss_weight: 5.0
disc_logit_reg: 0.01
disc_grad_penalty: 5
disc_weight_decay: 0.0001
disc_reward_scale: 2

diversity_weight: 0.01
diversity_tar: 1.0

enc_loss_weight: 5.0

latent_time_min: 0.0
latent_time_max: 5.0

task_reward_weight: 0.0
disc_reward_weight: 0.5
enc_reward_weight: 0.5

